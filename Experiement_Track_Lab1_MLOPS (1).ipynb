{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iO6aAI5iXk8_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import urllib.request\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# 1. W&B login and config\n",
        "# ---------------------------------------------------\n",
        "wandb.login()\n",
        "\n",
        "config = {\n",
        "    \"project_name\": \"Lab1-visualize-models\",\n",
        "    \"run_name\": \"keras-mlp-dermatology\",\n",
        "    \"test_size\": 0.2,\n",
        "    \"random_state\": 42,\n",
        "    \"batch_size\": 32,\n",
        "    \"epochs\": 60,\n",
        "    \"learning_rate\": 1e-3,\n",
        "    \"hidden_units\": [128, 64],\n",
        "    \"dropout_rate\": 0.25\n",
        "}\n",
        "\n",
        "run = wandb.init(\n",
        "    project=config[\"project_name\"],\n",
        "    name=config[\"run_name\"],\n",
        "    config=config\n",
        ")\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# 2. Download and load the Dermatology dataset\n",
        "# ---------------------------------------------------\n",
        "data_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/dermatology/dermatology.data\"\n",
        "data_path = \"dermatology.data\"\n",
        "\n",
        "if not os.path.exists(data_path):\n",
        "    urllib.request.urlretrieve(data_url, data_path)\n",
        "\n",
        "# The dataset has 34 feature columns + 1 label column (35 total)\n",
        "column_names = [f\"feat_{i}\" for i in range(34)] + [\"target\"]\n",
        "\n",
        "df = pd.read_csv(\n",
        "    data_path,\n",
        "    header=None,\n",
        "    names=column_names,\n",
        "    na_values=\"?\"\n",
        ")\n",
        "\n",
        "# Handle missing values (e.g., age) by filling with the column median\n",
        "df = df.fillna(df.median(numeric_only=True))\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# 3. Prepare features and labels\n",
        "# ---------------------------------------------------\n",
        "X = df.drop(\"target\", axis=1).values.astype(np.float32)\n",
        "y_raw = df[\"target\"].values.astype(int)\n",
        "\n",
        "# Original labels are 1..6, convert to 0..5\n",
        "y = y_raw - 1\n",
        "num_classes = len(np.unique(y))\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=config[\"test_size\"],\n",
        "    random_state=config[\"random_state\"],\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# 4. Build Keras MLP model\n",
        "# ---------------------------------------------------\n",
        "def build_model(input_dim, num_classes, cfg):\n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.Input(shape=(input_dim,)))\n",
        "\n",
        "    # Hidden layer 1\n",
        "    model.add(layers.Dense(cfg[\"hidden_units\"][0], activation=\"relu\"))\n",
        "    model.add(layers.Dropout(cfg[\"dropout_rate\"]))\n",
        "\n",
        "    # Hidden layer 2\n",
        "    model.add(layers.Dense(cfg[\"hidden_units\"][1], activation=\"relu\"))\n",
        "    model.add(layers.Dropout(cfg[\"dropout_rate\"]))\n",
        "\n",
        "    # Output layer\n",
        "    model.add(layers.Dense(num_classes, activation=\"softmax\"))\n",
        "\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=cfg[\"learning_rate\"])\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "model = build_model(\n",
        "    input_dim=X_train_scaled.shape[1],\n",
        "    num_classes=num_classes,\n",
        "    cfg=config\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# 5. Train the model with W&B logging\n",
        "# ---------------------------------------------------\n",
        "callbacks = [\n",
        "    WandbCallback(monitor=\"val_accuracy\", save_weights_only=False),\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\",\n",
        "        patience=8,\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_scaled,\n",
        "    y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=config[\"epochs\"],\n",
        "    batch_size=config[\"batch_size\"],\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# 6. Evaluate and log metrics\n",
        "# ---------------------------------------------------\n",
        "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
        "error_rate = 1.0 - test_accuracy\n",
        "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Test error rate: {error_rate:.4f}\")\n",
        "\n",
        "run.summary[\"test_accuracy\"] = test_accuracy\n",
        "run.summary[\"error_rate\"] = error_rate\n",
        "\n",
        "# Predictions for confusion matrix\n",
        "y_proba = model.predict(X_test_scaled)\n",
        "y_pred = np.argmax(y_proba, axis=1)\n",
        "\n",
        "# Log confusion matrix to W&B\n",
        "wandb.sklearn.plot_confusion_matrix(\n",
        "    y_test,\n",
        "    y_pred,\n",
        "    labels=list(range(num_classes))\n",
        ")\n",
        "\n",
        "run.finish()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sXy8UGnRX7gH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}